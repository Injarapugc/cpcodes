{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:37:55.173938Z",
     "iopub.status.busy": "2023-12-02T08:37:55.173546Z",
     "iopub.status.idle": "2023-12-02T08:37:56.199431Z",
     "shell.execute_reply": "2023-12-02T08:37:56.198249Z",
     "shell.execute_reply.started": "2023-12-02T08:37:55.173897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.0\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:41:43.753992Z",
     "iopub.status.busy": "2023-12-02T08:41:43.753563Z",
     "iopub.status.idle": "2023-12-02T08:42:06.436705Z",
     "shell.execute_reply": "2023-12-02T08:42:06.435412Z",
     "shell.execute_reply.started": "2023-12-02T08:41:43.753947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\anaconda\\envs\\medical\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.7\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.6.15  |       h5b45459_0         188 KB  cctbx202208\n",
      "    libsqlite-3.39.2           |       h8ffe710_1         637 KB  cctbx202208\n",
      "    openssl-1.1.1q             |       h8ffe710_0         5.8 MB  cctbx202208\n",
      "    pip-22.2.2                 |     pyhd8ed1ab_0         1.5 MB  cctbx202208\n",
      "    python-3.7.12              |h7840368_100_cpython        17.9 MB  cctbx202208\n",
      "    python_abi-3.7             |          2_cp37m           4 KB  cctbx202208\n",
      "    setuptools-59.8.0          |   py37h03978a9_1         1.0 MB  cctbx202208\n",
      "    sqlite-3.39.2              |       h8ffe710_1         660 KB  cctbx202208\n",
      "    ucrt-10.0.20348.0          |       h57928b3_0         1.2 MB  cctbx202208\n",
      "    vc-14.2                    |       hb210afc_6          13 KB  cctbx202208\n",
      "    vs2015_runtime-14.29.30037 |       h902a5da_6         1.3 MB  cctbx202208\n",
      "    wheel-0.37.1               |     pyhd8ed1ab_0          31 KB  cctbx202208\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        30.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ca-certificates    cctbx202208/win-64::ca-certificates-2022.6.15-h5b45459_0 \n",
      "  libsqlite          cctbx202208/win-64::libsqlite-3.39.2-h8ffe710_1 \n",
      "  openssl            cctbx202208/win-64::openssl-1.1.1q-h8ffe710_0 \n",
      "  pip                cctbx202208/noarch::pip-22.2.2-pyhd8ed1ab_0 \n",
      "  python             cctbx202208/win-64::python-3.7.12-h7840368_100_cpython \n",
      "  python_abi         cctbx202208/win-64::python_abi-3.7-2_cp37m \n",
      "  setuptools         cctbx202208/win-64::setuptools-59.8.0-py37h03978a9_1 \n",
      "  sqlite             cctbx202208/win-64::sqlite-3.39.2-h8ffe710_1 \n",
      "  ucrt               cctbx202208/win-64::ucrt-10.0.20348.0-h57928b3_0 \n",
      "  vc                 cctbx202208/win-64::vc-14.2-hb210afc_6 \n",
      "  vs2015_runtime     cctbx202208/win-64::vs2015_runtime-14.29.30037-h902a5da_6 \n",
      "  wheel              cctbx202208/noarch::wheel-0.37.1-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "python-3.7.12        | 17.9 MB   |            |   0% \n",
      "\n",
      "setuptools-59.8.0    | 1.0 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "vs2015_runtime-14.29 | 1.3 MB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.39.2     | 637 KB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.39.2        | 660 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1q       | 5.8 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.2              | 13 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.37.1         | 31 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.20348.0    | 1.2 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.7       | 4 KB      |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-22.2.2           | 1.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2022 | 188 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.39.2     | 637 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libsqlite-3.39.2     | 637 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.39.2        | 660 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sqlite-3.39.2        | 660 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vs2015_runtime-14.29 | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "vs2015_runtime-14.29 | 1.3 MB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "setuptools-59.8.0    | 1.0 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "setuptools-59.8.0    | 1.0 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.2              | 13 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "vc-14.2              | 13 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.7       | 4 KB      | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.7       | 4 KB      | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2022 | 188 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2022 | 188 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.20348.0    | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ucrt-10.0.20348.0    | 1.2 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-22.2.2           | 1.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pip-22.2.2           | 1.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1q       | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1q       | 5.8 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "python-3.7.12        | 17.9 MB   | ########## | 100% \n",
      "python-3.7.12        | 17.9 MB   | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate medical\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "'source' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!conda create -n medical -c cctbx202208 python=3.7 -y\n",
    "!source /opt/conda/bin/activate medical && conda install -c cctbx202208 python=3.7 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:42:38.15481Z",
     "iopub.status.busy": "2023-12-02T08:42:38.153771Z",
     "iopub.status.idle": "2023-12-02T08:42:41.192987Z",
     "shell.execute_reply": "2023-12-02T08:42:41.191602Z",
     "shell.execute_reply.started": "2023-12-02T08:42:38.154764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n",
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!/opt/conda/envs/medical/bin/python3 --version\n",
    "!echo 'print(\"Hello, World!\")' > test.py\n",
    "!/opt/conda/envs/medical/bin/python3 test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:43:48.064169Z",
     "iopub.status.busy": "2023-12-02T08:43:48.063745Z",
     "iopub.status.idle": "2023-12-02T08:43:50.156184Z",
     "shell.execute_reply": "2023-12-02T08:43:50.155019Z",
     "shell.execute_reply.started": "2023-12-02T08:43:48.064134Z"
    }
   },
   "outputs": [],
   "source": [
    "!sudo rm /opt/conda/bin/python3\n",
    "!sudo ln -sf /opt/conda/envs/medical/bin/python3 /opt/conda/bin/python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:44:19.744238Z",
     "iopub.status.busy": "2023-12-02T08:44:19.743867Z",
     "iopub.status.idle": "2023-12-02T08:44:20.767547Z",
     "shell.execute_reply": "2023-12-02T08:44:20.766205Z",
     "shell.execute_reply.started": "2023-12-02T08:44:19.744207Z"
    }
   },
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T09:02:00.761075Z",
     "iopub.status.busy": "2023-12-02T09:02:00.76066Z",
     "iopub.status.idle": "2023-12-02T09:03:28.047464Z",
     "shell.execute_reply": "2023-12-02T09:03:28.046258Z",
     "shell.execute_reply.started": "2023-12-02T09:02:00.761039Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r /kaggle/input/full-req-chex/full_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from CNN_encoder import CNN_Encoder\n",
    "from configs import argHandler\n",
    "import time\n",
    "from medical_w2v_wrapper import Medical_W2V_Wrapper\n",
    "from tokenizer_wrapper import TokenizerWrapper\n",
    "import matplotlib.pyplot as plt\n",
    "from utility import get_optimizer, get_enqueuer\n",
    "import os\n",
    "import json\n",
    "from augmenter import augmenter\n",
    "from gpt2.gpt2_model import TFGPT2LMHeadModel\n",
    "from test import evaluate_enqueuer\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Allow memory growth for GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import argHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a arghandler class which takes care of initalizing all the variables\n",
    "\n",
    "FLAGS = argHandler()\n",
    "FLAGS.setDefaults()\n",
    "tf.keras.backend.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL THE VARIABLES INITIALIZED BY ARGHANDLER\n",
    "FLAGS.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FLAGS.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then we are tokenizing all the words in our captions data set #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer wrapper takes the arguments\n",
    "\n",
    "### csv Dataset containing image and captions\n",
    "### Name of the Column containing caption\n",
    "### Max Length of Sequence - 200\n",
    "### Vocab_Size - 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_wrapper = TokenizerWrapper(FLAGS.all_data_csv, FLAGS.csv_label_columns[0],\n",
    "                                     FLAGS.max_sequence_length, FLAGS.tokenizer_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_wrapper.get_token_of_word(\"we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enqueuer, train_steps = get_enqueuer(FLAGS.train_csv, FLAGS.batch_size, FLAGS, tokenizer_wrapper)\n",
    "test_enqueuer, test_steps = get_enqueuer(FLAGS.test_csv, 1, FLAGS, tokenizer_wrapper)\n",
    "batch_test_enqueuer, batch_test_steps = get_enqueuer(FLAGS.test_csv, FLAGS.batch_size, FLAGS, tokenizer_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enqueuer.start(workers=FLAGS.generator_workers, max_queue_size=FLAGS.generator_queue_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads the 400D embeddings matrix frm gensim\n",
    "\n",
    "medical_w2v = Medical_W2V_Wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SAVES WORD EMBEDDINGS FOR ALL THE WORDS IN OUR REPORTS DATASET\n",
    "medical_w2v.save_embeddings(tokenizer_wrapper.get_word_tokens_list(),FLAGS.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer_wrapper.get_word_tokens_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETS WORD EMBEDDINGS FOR ALL THE WORDS IN OUR REPORTS DATASET\n",
    "embeddings = medical_w2v.get_embeddings_matrix_for_words(tokenizer_wrapper.get_word_tokens_list(),\n",
    "                                                          FLAGS.tokenizer_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_embeddings = medical_w2v.get_embeddings_matrix_for_tags(FLAGS.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tags Embeddings shape: {tags_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del medical_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_encoder import CNN_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder('pretrained_visual_model', FLAGS.visual_model_name, FLAGS.visual_model_pop_layers,\n",
    "                      FLAGS.encoder_layers,\n",
    "                      FLAGS.tags_threshold, tags_embeddings, FLAGS.finetune_visual_model, len(FLAGS.tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_enqueuer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_img,t_target, _ = next(train_generator)\n",
    "print(type(t_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_v, t_embed = encoder(t_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_embed[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2.gpt2_model import TFGPT2LMHeadModel\n",
    "decoder = TFGPT2LMHeadModel.from_pretrained('distilgpt2', from_pt=True, resume_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(FLAGS.optimizer_type, FLAGS.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, tokenizer_wrapper.GPT2_pad_token_id()))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, target, test_mode=False):\n",
    "    with tf.GradientTape() as tape:\n",
    "        visual_features, tags_embeddings = encoder(images)\n",
    "        dec_input = target[:, 0:-1]\n",
    "\n",
    "        # passing the features through the decoder\n",
    "        predictions, _ = decoder(dec_input, visual_features=visual_features, tags_embeddings=tags_embeddings, past=None)\n",
    "\n",
    "        loss = loss_function(target[:, 1:], predictions)\n",
    "    if not test_mode:\n",
    "        trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(os.path.join(FLAGS.ckpt_path, 'best_ckpt'))\n",
    "except:\n",
    "    print(\"path already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FLAGS.ckpt_path, 'configs.json'), 'w') as fp:\n",
    "    json.dump(FLAGS, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_manager = tf.train.CheckpointManager(ckpt, FLAGS.ckpt_path, max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "best_test_avg_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_score(scores_dict):\n",
    "    avg_score = 0\n",
    "    for value in scores_dict.values():\n",
    "        avg_score += value\n",
    "    avg_score = avg_score / len(scores_dict)\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ckpt_manager.latest_checkpoint and FLAGS.continue_from_last_ckpt:\n",
    "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Restored from checkpoint: {}\".format(ckpt_manager.latest_checkpoint))\n",
    "    try:\n",
    "        with open(os.path.join(FLAGS.ckpt_path, 'scores.json')) as scores_file:\n",
    "            scores = json.load(scores_file)\n",
    "            best_test_avg_score = get_avg_score(scores)\n",
    "            print(f\"best scores: {scores}\")\n",
    "    except:\n",
    "        print(\"No previous scores found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_losses_csv = {\"step\": [], \"batch_loss\": []}\n",
    "test_batch_losses_csv = {\"step\": [], \"batch_loss\": []}\n",
    "train_after_batch_losses_csv = {\"step\": [], \"batch_loss\": []}\n",
    "losses_csv = {\"epoch\": [], \"train_loss\": [], \"train_after_loss\": [], \"test_loss\": []}\n",
    "time_csv = {\"epoch\": [], 'time_taken': [], \"scores\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_loss(enqueuer, steps, batch_losses_csv):\n",
    "    tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "    if not enqueuer.is_running():\n",
    "        enqueuer.start(workers=FLAGS.generator_workers, max_queue_size=FLAGS.generator_queue_length)\n",
    "    generator = enqueuer.get()\n",
    "\n",
    "    batch_losses = []\n",
    "    total_loss = 0\n",
    "    step = 0\n",
    "    for batch in range(steps):\n",
    "        img, target, _ = next(generator)\n",
    "        batch_loss = train_step(img, target, True)\n",
    "        batch_losses_csv['step'].append(step)\n",
    "        batch_losses_csv['batch_loss'].append(batch_loss.numpy())\n",
    "        total_loss += batch_loss\n",
    "        batch_losses.append(batch_loss)\n",
    "        step += 1\n",
    "    epoch_loss = total_loss / generator.steps\n",
    "    enqueuer.stop()\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "\n",
    "    return epoch_loss, batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_enqueuer.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, 1):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    times_to_get_batch = 0\n",
    "    pure_training_time = 0\n",
    "    step = 0\n",
    "    # for batch in range(train_steps):\n",
    "    for batch in range(1):\n",
    "        t = time.time()\n",
    "        img, target, _ = next(train_generator)\n",
    "        print(\"Time to get batch: {} s \".format(time.time() - t))\n",
    "        if time.time() - t > 2:\n",
    "            times_to_get_batch += 1\n",
    "        step_time = time.time()\n",
    "        batch_loss = train_step(img, target)\n",
    "        pure_training_time += time.time() - step_time\n",
    "        total_loss += batch_loss\n",
    "        step += 1\n",
    "        train_batch_losses_csv['step'].append(step)\n",
    "        train_batch_losses_csv['batch_loss'].append(batch_loss.numpy())\n",
    "\n",
    "        print(\"Time to train step: {} s \".format(time.time() - t))\n",
    "\n",
    "        if batch % 1 == 0 and batch > 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                epoch + 1, batch, batch_loss.numpy()))\n",
    "    # storing the epoch end loss value to plot later'\n",
    "    total_loss = (total_loss / train_steps).numpy()\n",
    "    loss_plot.append(total_loss)\n",
    "    print('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                        total_loss))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    print('Batches that took long: {}'.format(times_to_get_batch))\n",
    "    if FLAGS.calculate_loss_after_epoch:\n",
    "        test_epoch_loss, _ = get_overall_loss(batch_test_enqueuer, batch_test_steps, test_batch_losses_csv)\n",
    "        train_epoch_loss, _ = get_overall_loss(train_enqueuer, train_steps, train_after_batch_losses_csv)\n",
    "        losses_csv['train_after_loss'].append(train_epoch_loss.numpy())\n",
    "        losses_csv['test_loss'].append(test_epoch_loss.numpy())\n",
    "    else:\n",
    "        losses_csv['train_after_loss'].append('-')\n",
    "        losses_csv['test_loss'].append('-')\n",
    "    losses_csv[\"epoch\"].append(epoch + 1)\n",
    "    losses_csv['train_loss'].append(total_loss)\n",
    "\n",
    "    pd.DataFrame(losses_csv).to_csv(os.path.join(FLAGS.ckpt_path, 'losses.csv'), index=False)\n",
    "    pd.DataFrame(train_batch_losses_csv).to_csv(os.path.join(FLAGS.ckpt_path, 'train_batch_losses.csv'), index=False)\n",
    "    pd.DataFrame(train_after_batch_losses_csv).to_csv(os.path.join(FLAGS.ckpt_path, 'train_after_batch_losses.csv'),\n",
    "                                                      index=False)\n",
    "    pd.DataFrame(test_batch_losses_csv).to_csv(os.path.join(FLAGS.ckpt_path, 'test_batch_losses.csv'), index=False)\n",
    "    ckpt_manager.save()\n",
    "\n",
    "    plt.plot(loss_plot)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Plot')\n",
    "    plt.savefig(FLAGS.ckpt_path + \"/loss.png\")\n",
    "\n",
    "    if epoch % FLAGS.epochs_to_evaluate == 0 and epoch > 0:\n",
    "        current_avg_score = 0\n",
    "        print(\"Evaluating on test set..\")\n",
    "        train_enqueuer.stop()\n",
    "        current_scores = evaluate_enqueuer(test_enqueuer, test_steps, FLAGS, encoder, decoder, tokenizer_wrapper)\n",
    "        time_csv['epoch'].append(epoch + 1)\n",
    "        time_csv['time_taken'].append(pure_training_time)\n",
    "        time_csv['scores'].append(current_scores)\n",
    "        df = pd.DataFrame(time_csv)\n",
    "        df.to_csv(os.path.join(FLAGS.ckpt_path, 'time.csv'), index=False)\n",
    "        current_avg_score = get_avg_score(current_scores)\n",
    "        train_enqueuer.start(workers=FLAGS.generator_workers, max_queue_size=FLAGS.generator_queue_length)\n",
    "        if best_test_avg_score == 0 or current_avg_score > best_test_avg_score:\n",
    "            print(f\"found a new best model and saving the ckpt\")\n",
    "            shutil.rmtree(os.path.join(FLAGS.ckpt_path, 'best_ckpt'))\n",
    "            os.mkdir(os.path.join(FLAGS.ckpt_path, 'best_ckpt'))\n",
    "            for filename in glob(os.path.join(FLAGS.ckpt_path, '*')):\n",
    "                if os.path.isfile(filename):\n",
    "                    shutil.copy(filename, os.path.join(FLAGS.ckpt_path, 'best_ckpt'))\n",
    "            best_test_avg_score = current_avg_score\n",
    "\n",
    "\n",
    "train_enqueuer.stop()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4046038,
     "sourceId": 7033663,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4095481,
     "sourceId": 7104204,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
